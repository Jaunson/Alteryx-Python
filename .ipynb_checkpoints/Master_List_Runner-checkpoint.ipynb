{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ayx import Alteryx\n",
    "    \n",
    "try:\n",
    "    from multiprocess import process, pool\n",
    "except:\n",
    "    Alteryx.installPackages('multiprocess')\n",
    "    from multiprocess import process, pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries required to process the data and send out alerts\n",
    "import pandas as pd\n",
    "\n",
    "# Reads in paths to the workflows and counts the number of them                 \n",
    "paths = Alteryx.read(\"#1\")\n",
    "count_of_flows = paths.FullPath.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the actual runner, essentially it uses AlteryxEngineCmd.exe to execute workflows and has\n",
    "a timeout function - if any workflow takes more than 40 minutes (default time) it is \n",
    "automatically killed and the runner carries on to the next flow.\n",
    "\n",
    "The worker then parses the results and sends them out to be read or carried into another function\n",
    "\n",
    "Essential libraries are called from within the function itself because when the function is ran\n",
    "in parallel it will be ran as it's own process.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def worker(path):\n",
    "    from datetime import timedelta, time as timeobj\n",
    "    import pandas as pd\n",
    "    import subprocess\n",
    "    import time\n",
    "    import re\n",
    "    from socket import gethostname\n",
    "    def workflow_runner(location):\n",
    "        start = time.time()\n",
    "        try:\n",
    "            output = subprocess.check_output([f'\\\\\\{gethostname()}\\Alteryx\\\\bin\\AlteryxEngineCmd.exe',\n",
    "                                              location],timeout=2400)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            output = e.output\n",
    "        except subprocess.TimeoutExpired:\n",
    "            output = str('\\r\\n Timeout Error, workflow finished with 1 errors \\r\\n').encode(\"cp437\")\n",
    "        end = time.time()-start\n",
    "        return output, end\n",
    "    def result_parser(output,end):\n",
    "        warn = re.compile(r\"\\d+\\swarnings\")\n",
    "        error =  re.compile(r\"\\d+\\serrors\")\n",
    "        conversion_err = re.compile(r\"\\d+\\sfield conversion errors\")\n",
    "        seconds = re.compile(r\"\\d+\\.\\d\\d\\d\")\n",
    "        t= time.localtime()\n",
    "        current_time = time.strftime(\"%m/%d/%Y %H:%M:%S\", t)\n",
    "        try:\n",
    "            warnings = [int(warn\n",
    "                            .findall(output.decode(\"cp437\")\n",
    "                            .split('\\r\\n')[-2])[0]\n",
    "                            .split(\" \")[0])]\n",
    "        except:\n",
    "            warnings = [0]\n",
    "        try:\n",
    "            errors = [int(error\n",
    "                          .findall(output.decode(\"cp437\")\n",
    "                          .split('\\r\\n')[-2])[0]\n",
    "                          .split(\" \")[0])]\n",
    "        except:\n",
    "            errors = [0]    \n",
    "        try:\n",
    "            conversion = [int(conversion_err\n",
    "                              .findall(output.decode(\"cp437\")\n",
    "                              .split('\\r\\n')[-2])[0]\n",
    "                              .split(\" \")[0])]\n",
    "        except:\n",
    "            conversion = [0]\n",
    "        try:\n",
    "            duration = [end]\n",
    "        except:\n",
    "            duration = [timeobj(0,0,0)]\n",
    "        workflow = pd.DataFrame({\"Output\":[output.decode(\"cp437\").split('\\r\\n')[-2]],\n",
    "                                     \"Warnings\":warnings,\n",
    "                                     \"Conversion Errors\":conversion,\n",
    "                                     \"Errors\":errors,\n",
    "                                     \"Log\":[output.decode(\"cp437\")],\n",
    "                                     \"File\":path.split('\\\\')[-1][:-5],\n",
    "                                     \"ModuleFullPath\":path,\n",
    "                                     \"MasterRunTime\":current_time,\n",
    "                                     \"Time\":duration})\n",
    "        return workflow\n",
    "    results, finish = workflow_runner(path)\n",
    "    return result_parser(results, finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emailer function used in the workflow when list runner takes too long\n",
    "def emailer(email):\n",
    "    import smtplib\n",
    "    from email.message import EmailMessage\n",
    "    msg = EmailMessage()\n",
    "    warning_time = time.strftime('%H:%M:%S', time.gmtime(email['Total Time (seconds)'][0]))\n",
    "    msg['Subject'] = f'**ALERT: List Runner has been running for {warning_time}**'\n",
    "    msg['From'] = from_email # set up an email address for the email to come from\n",
    "    msg['To'] = email['Addresses'][0]\n",
    "    \n",
    "    msg.set_content(f\"\"\"\n",
    "    Hello!\n",
    "\n",
    "    The list runner has currently finished {email['Completed Flows'][0]} of {email['Total Workflows'][0]} workflows and has been running for {warning_time}!\n",
    "\n",
    "    Can you please take a few minutes to investigate or kill the list runner?\n",
    "\n",
    "    Respectfully,\n",
    "    List Runner\n",
    "    \"\"\")\n",
    "\n",
    "    s = smtplib.SMTP(smtp_relay) # alter this to the applicable SMTP relay\n",
    "    s.send_message(msg)\n",
    "    s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the alert function, it checks that the total list runner time is still under dafault_duration\n",
    "# If the list runner is over 2.5 hours (default) - it sends an email out with the current progress / run time\n",
    "\n",
    "def duration_alert(duration,completed_flows):\n",
    "    if duration >= 9000:\n",
    "        emails = pd.DataFrame({'Addresses':[to_email],\n",
    "                               'Total Workflows':[count_of_flows],\n",
    "                               'Completed Flows':[completed_flows],\n",
    "                               'Total Time (seconds)':[duration]})\n",
    "        emailer(emails)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\"\"\"\n",
    "This is the actually list_runner that uses the worker and alert functions to run and alert\n",
    "users - it then outputs a df of metrics similar to the original list runner.\n",
    "\n",
    "The \"processes\" variable is using the pool function to let the system know how many \n",
    "concurrent workers to run at once. We default at 2 but this number can be increased \n",
    "please consider the specifications of your system and the volume of data brought in\n",
    "memory in each workflow when increasing the number of concurrent processes.\n",
    "\"\"\" \n",
    "\n",
    "def list_runner(list_of_paths):\n",
    "    df = pd.DataFrame({\"Output\":[],\n",
    "                        \"Warnings\":[],\n",
    "                        \"Conversion Errors\":[],\n",
    "                        \"Errors\":[],\n",
    "                        \"Log\":[],\n",
    "                        \"File\":[],\n",
    "                        \"ModuleFullPath\":[],\n",
    "                        \"MasterRunTime\":[],\n",
    "                        \"Time\":[]})\n",
    "    t = 0\n",
    "    flows = 0\n",
    "    processes = pool.Pool(2)\n",
    "    for item in processes.map(worker, list_of_paths):\n",
    "        t2 = time.time()\n",
    "        df = df.append(item)\n",
    "        t3 = time.time() - t2\n",
    "        t+=t3 \n",
    "        flows +=1\n",
    "        duration_alert(t,flows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is where the list runner is actually executed against the paths supplied to it.\n",
    "Those results then have some additional logic applied to pull out before being\n",
    "output to Alteryx.\n",
    "\"\"\"\n",
    "workflows =  list_runner(paths['FullPath'])\n",
    "result_test = lambda x: \"Succeeded\" if (x == 0) else \"Failed\"\n",
    "seconds_conversion = lambda x: timedelta(seconds=x)\n",
    "workflows['Result'] = list(map(result_test,workflows['Errors']))\n",
    "workflows['Time'] = list(map(seconds_conversion,workflows['Time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the cell that supplies to the results of the list runner to the first python output\n",
    "Alteryx.write(workflows,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
